# Architecture Design Decisions for Ray Data Preparation and HPC on Cloud
This work aims to evaluate a two phased architecture approach as an framework to address the current needs for highly scalable pre-processing, storage and specific numeric simulation purposes.



<img src="../images/AWS_VectorMachine_Ray-HPC-architecture.drawio.svg" alt="AWS Architecture" width="500">

**Figure 4:** Here the end‐to‐end pipeline architecture into a clean two‐phase pattern (Ray to HPC)


Modular components is a key best practice for High-Performance Computing (HPC) workloads on Amazon Web Services (AWS), contributing to improved operational efficiency and reduced manual intervention. This approach is crucial for managing complex applications and facilitating continuous development practices in the cloud environment.

The Figure 4 shows the end‐to‐end pipeline, whereas following further view into the two‐phase pattern:


# Ray load DNA sequencing file to vectorize-generate embeddings to downstream the output in the HPC cluster
The two-phase pipeline - as the Figure 3 shows - moving from data preprocessing to feeding a numerical simulation, is a common and critical workflow in HPC and Machine Learning, especially when dealing with large, complex datasets like genomic sequences or simulation outputs involves overcoming challenges related to data volume, variety, and velocity.

The first phase focuses on preparing vast, often raw and unstructured, datasets into a clean, transformed, and properly formatted state suitable for numerical simulation or complex model training.

The second phase involves executing the core computational models or algorithms using the preprocessed data. These applications are often "compute-intensive" and require significant parallel processing capabilities.

Here is an elaboration of the main steps and tasks for each phase, highlighting where Ray and AWS cloud-based HPC services fit in.



**Most common scientific data pre-processing steps needs before numerical simulation needs:**


 | Step                                    | MD (Molecular Dynamics)                                                                                    | CFD (Computational Fluid Dynamics)                                                                                            | FFT (Spectral Analysis)                                        | Genomics / Protein Sequencing                                                                     |
| --------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| **Validation & Cleaning**               | • Fix missing atoms/residues<br>• I/O: small text files, many parses<br>• CPU‐bound serial cleanup         | • Geometry repair, ensure watertight meshes<br>• I/O: CAD formats heavy parsing<br>• Memory: storing geometry                 | • Window selection, denoising<br>• CPU‐light, GPU‐trivial      | • Sequence QC, adapter trimming<br>• I/O: FASTQ large files<br>• Irregular string parses          |
| **Setup & Discretization**              | • Box definitions, coordinate conversion<br>• Memory: atom arrays<br>• GPU: cell lists for neighbor search | • Mesh generation (unstructured/tet/hexa)<br>• Compute: meshing algorithms (serial/p threaded)<br>• Memory: large mesh in RAM | • Signal framing, padding<br>• Low compute; trivial memory     | • k-mer indexing, suffix arrays<br>• Memory: huge hash tables<br>• Parallel: distributed indexing |
| **Partitioning & Chunking**             | • Split trajectory into frame blocks<br>• I/O throughput: binary streams<br>• Memory: chunk fits node      | • Domain decomposition subdomains<br>• I/O: writing mesh partitions<br>• Compute: balance & load distribution                 | • Segmenting time series<br>• Minimal I/O; in‐memory slicing   | • Batch reads for alignment<br>• I/O: S3/FSx streaming needed                                     |
| **Computation**                         | • Integration kernels (Verlet)<br>• GPU: OpenMM, CUDA acceleration<br>• Compute‐bound with data locality   | • Solver loops (Navier–Stokes)<br>• Memory‐bandwidth bound<br>• GPU: CuPHY or OpenCL solvers                                  | • FFT kernels (cuFFT / FFTW)<br>• Highly optimized GPU libs    | • Alignment (BWA, Bowtie) or assembly<br>• Irregular memory access; vectorization possible        |
| **Feature Extraction & Transformation** | • Compute distances, RDFs, contact maps<br>• CPU/GPU transforms<br>• Memory: distance matrices             | • Extract forces, pressure coefficients<br>• CPU heavy reductions<br>• Memory: scalar fields                                  | • Spectral feature extraction<br>• GPU trivial with transforms | • Variant calling, motif detection<br>• Compute: HMMs; I/O: reference lookups                     |
| **Serialization & Storage**             | • HDF5 or NetCDF writes<br>• I/O bound, parallel HDF5 recommended                                          | • VTK, CGNS, NetCDF outputs<br>• Storage: large binary dumps                                                                  | • Binary arrays, Parquet<br>• Minimal size                     | • Parquet/CSV for variants<br>• Metadata catalogs, many small files                               |

**Table 1:** Phase 1 regular steps for some scientific modeling & simulation context domain

<img src="../images/Generalized_data-pipeline.drawio.png" alt="Common ETL" width="500">
**Figure 3:** Processes and Storage schema for the most common steps in a two-phased data pipeline pattern

## Recipe: Two-Phase Pipeline on AWS

**Phase 1 – Ray-based Embedding Generation**
The `dna_embeddings.py` is packaged into a Docker image with GPU support. The **Ray autoscaler** config (`ray-cluster-example-full.yaml`) is part of a CloudFormation stack — using a custom resource or a simple CodeBuild project that runs `ray up` automatically whenever you push to `main`. With that in place, the CI-CD pipeline (CodePipeline → CodeBuild) will:

1. Build & push the GPU‐enabled Docker image to ECR.
2. Deploy or update the Ray cluster via the autoscaler YAML (executed from CodeBuild).
3. SSH into the head node to kick off your embedding job:

   ```bash
   ray submit ray-cluster-example-full.yaml dna_embeddings.py \
     -- args --input s3://my-bucket-xxx/raw/genomes/sample1.fq \
            --output s3://my-bucket-xxx/embeddings/sample1.parquet
   ```

By embedding S3 paths, Ray tasks will spin up GPU actors on the worker nodes, load the FASTQ file, apply ProtBERT encoder, and write out Parquet shards of `(N × D)` floats.

**Phase 2 – MPI-Driven Numeric Simulation**
While Phase 1 runs, in parallel a second CloudFormation template for **AWS ParallelCluster** (or can be used the built-in `pcluster` CLI). That template (`parallelcluster-config.yaml`) declares the Slurm head node, GPU/CPU compute fleet, FSx for Lustre, EFA networking, and a bootstrap action to `git clone` the application repo and compile `mpi_dna_seq.cpp`. Once embeddings land in S3/FSx, Slurm users can submit:

```bash
sbatch run_sim.sh sample1.parquet
```

where `run_sim.sh` looks like:

```bash
#!/bin/bash
#SBATCH --job-name=dna-sim
#SBATCH --ntasks=16
#SBATCH --gres=gpu:1
srun ./mpi_dna_seq mpi_input --embeddings s3://my-bucket-xxx/embeddings/sample1.parquet
```

Under the hood, the MPI code reads the Parquet vectors (via Arrow or custom reader), performs the simulation kernel-solver, and writes out results to Lustre.

**Automation & Monitoring**
Tie both stacks into a single **CodePipeline**:

* **Source**: GitHub
* **Build**: CodeBuild for Docker + CloudFormation deploy
* **Deploy**: CloudFormation update stacks for Ray and ParallelCluster

Use CloudWatch alarms on Ray’s autoscaler logs (Dashboard port 8265) and Slurm job throughput. Metrics like pending tasks or job queue length can trigger Lambda to scale the HPC fleet up/down.

---

### The execution of the applications Ray -> HPC-MPI

```bash
# Phase 1: Submit embedding job via Ray CLI
ray submit ray-cluster-example-full.yaml dna_embeddings.py \
  --args \
    --input s3://genomics-data/raw/sample1.fq \
    --output s3://genomics-data/embeddings/sample1.parquet \
    --batch-size 1024 --num-gpus 1

# Phase 2: Submit MPI simulation job on ParallelCluster
sbatch << 'EOF'
#!/bin/bash
#SBATCH --job-name=dna-sim
#SBATCH --ntasks=32
#SBATCH --gres=gpu:1
#SBATCH --time=02:00:00
module load mpi
srun ./mpi_dna_seq \
  --embeddings /fsx/embeddings/sample1.parquet \
  --output /fsx/results/sample1_sim.nc
EOF
```

This snippet demonstrates how to invoke each phase from the head nodes — embedding generation via Ray on GPU nodes, followed by an HPC scale MPI job consuming those embeddings. Continuous deployment and CloudWatch monitoring then ensure the two-phase pipeline stays healthy and cost-efficient.

### Ray application to ensure GPU cards will be used for acceleration in the embeddings generation

```python
# code/ray_app/dna_embeddings.py
    ...
    embedded = ds.map_batches(
        ComputeDNAEmbeddings,
        batch_size=32,               # tune for memory
        fn_constructor_kwargs={
            "seq_col": "sequence",
            "model_name": HF_MODEL,
            "device": "cpu",         # or "cuda"
        },
        concurrency=4,               # number of actors
        num_gpus=2,                  # set >0 if using GPUs
    )
    embedded.write_parquet(OUTPUT_PATH, try_create_dir=True)
    print("Embeddings written to", OUTPUT_PATH)
```