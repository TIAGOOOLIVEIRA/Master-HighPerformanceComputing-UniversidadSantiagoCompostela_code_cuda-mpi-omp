{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCyYK3kvupIq"
   },
   "source": [
    "## Deliverable 1: BASELINE - Baseline implementation (Due 30th september 2024)\n",
    "\n",
    "Using BERT-Base model (https://huggingface.co/google-bert/bert-base-uncased) and SQUAD dataset (https://rajpurkar.github.io/SQuAD-explorer/), you have to select an implementation in Pytorch for its training using a single GPU. This implementation will be called in the following the **BASELINE implementation**. In order to generate this implementation you can search for one on the Internet, as the ability to generate such an implementation from scratch is probably beyond your expertise.\n",
    "\n",
    "You have to measure the training time for that code using one single GPU. If the time is too small (less than one minute), maybe you can add more epochs to the training or look for a larger data set or more sophisticated model architecture.\n",
    "\n",
    "If you are able to provide a profiling of the training using Tensorboard or any other tool, that will be a plus in your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhiieUfhp8Ou"
   },
   "source": [
    "# BASELINE SINGLE GPU\n",
    "\n",
    "Using BERT-Base model (https://huggingface.co/google-bert/bert-base-uncased) and SQUAD dataset (https://rajpurkar.github.io/SQuAD-explorer/)\n",
    "\n",
    "The objectives of the task is to measure training time using a single GPU Nvidia A100\n",
    "\n",
    "Optional: Profiling of the training using Tensorboard\n",
    "\n",
    "RESOURCES\n",
    "https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/question_answering.ipynb#scrollTo=jwMn3_6gx6P8\n",
    "\n",
    "https://www.youtube.com/watch?v=wG2J_MJEjSQ\n",
    "\n",
    "https://www.youtube.com/watch?v=IcrN_L2w0_Y\n",
    "\n",
    "https://lightning.ai/pages/community/tutorial/how-to-speed-up-pytorch-model-training/\n",
    "\n",
    "https://datasets.activeloop.ai/docs/ml/datasets/squad-dataset/\n",
    "\n",
    "https://knswamy.medium.com/nlp-deep-learning-training-on-downstream-tasks-using-pytorch-lightning-question-answering-on-17d2a0965733\n",
    "\n",
    "https://pytorch.org/text/0.9.0/_modules/torchtext/datasets/squad2.html\n",
    "\n",
    "https://pytorchnlp.readthedocs.io/en/latest/_modules/torchnlp/datasets/squad.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1727708042077,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "ZRBEFBIOYnZm",
    "outputId": "b05beea9-ac8b-45cd-b5b0-8fcc821e382e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4939,
     "status": "ok",
     "timestamp": 1727708047549,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "A8tP2Bs0TWIH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3a11f8d5-1f3f-432c-bdeb-a83c0948767c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# run this cell, then restart the runtime before continuing\n",
    "# !pip install datasets transformers --quiet\n",
    "! pip install -q transformers[torch] datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2335,
     "status": "ok",
     "timestamp": 1727708049879,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "Hin0H6oQY79I",
    "outputId": "46a31043-f077-48e5-93d2-13edeb51ffa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning --quiet\n",
    "#!pip install colorama --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzNMjQUGegxS"
   },
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1727708052149,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "pBxOe0fMsBnD",
    "outputId": "1a6d5aa7-2822-49d9-de62-a42c3f2ddc80"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7204db0024b4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msquad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"squad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Load the dataset\n",
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1727708050398,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "PTNmlhlQsSnv"
   },
   "outputs": [],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1727708050399,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "TflAp3HJsvlk"
   },
   "outputs": [],
   "source": [
    "\n",
    "example = squad['train'][10]\n",
    "for key in example:\n",
    "    print(key, \":\", example[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1727708050399,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "Y78-XHkoetGZ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1727708050399,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "qBBeWA8Kspj_"
   },
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride.\n",
    "    # This results in one example possible giving several features when a context is long,\n",
    "    # each of those features having a context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",  # truncate context, not the question\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context.\n",
    "    # This will help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1727708050399,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "a86CrmGctIHs"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Apply the function to our data\n",
    "tokenized_datasets = squad.map(prepare_train_features, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1727708050399,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "RzqOfnm9tLwN"
   },
   "outputs": [],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1727708050399,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "E15Z4dwjtPng"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050399,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "6Dx1T8BGtR5J"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"finetune-BERT-squad\",\n",
    "    #eval_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "McsC2tuXtpbQ"
   },
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "QZu4eMQktrEh"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(1000)),\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].select(range(100)),\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "Mg3JdbgbtuYh"
   },
   "outputs": [],
   "source": [
    "# Run the trainer\n",
    "import torch\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLgnoQ-LCcwA"
   },
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "8PELw4C1Cjye"
   },
   "outputs": [],
   "source": [
    "instance = squad['train'][20]\n",
    "context = instance['context']\n",
    "question = instance['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "TPfNaZm2CsOJ"
   },
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "x8kTAndQEWrA"
   },
   "outputs": [],
   "source": [
    "instance['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "yIVi-38GCv4K"
   },
   "outputs": [],
   "source": [
    "\n",
    "given_answer = instance['answers']['text'][0]  # Assuming the first answer is the correct one\n",
    "given_answer_start = instance['answers']['answer_start'][0]\n",
    "given_answer, given_answer_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1727708050400,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "5n1VJfvoDOEm"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "u8jIog5eEgHk"
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "AGjeIdnsEj9b"
   },
   "outputs": [],
   "source": [
    "inputs = {k: v.to(device) for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "iXHu0cSnDSyY"
   },
   "outputs": [],
   "source": [
    "# Get model's output\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "glGpWh68DU0t"
   },
   "outputs": [],
   "source": [
    "# Get the predicted answer\n",
    "start_idx = torch.argmax(output.start_logits)\n",
    "end_idx = torch.argmax(output.end_logits)\n",
    "\n",
    "predicted_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_idx:end_idx + 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "_OZO8dgpENlh"
   },
   "outputs": [],
   "source": [
    "predicted_answer, start_idx, end_idx, start_idx.item(), end_idx.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "ODGgHNDwDXDc"
   },
   "outputs": [],
   "source": [
    "correct = (predicted_answer.lower() == given_answer.lower())\n",
    "evaluation = 'Correct' if correct else f'Incorrect (Predicted: {predicted_answer}, Given: {given_answer})'\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "eTTGC1ihDgDu"
   },
   "outputs": [],
   "source": [
    "# Function to evaluate a single instance\n",
    "def evaluate_instance(instance, device):\n",
    "    context = instance['context']\n",
    "    question = instance['question']\n",
    "    given_answer = instance['answers']['text'][0]  # Assuming the first answer is the correct one\n",
    "\n",
    "    # Tokenize the data\n",
    "    inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Apply the BERT model\n",
    "    with torch.no_grad():  # No need to calculate gradients\n",
    "        output = model(**inputs)\n",
    "\n",
    "    # Get the predicted answer\n",
    "    start_idx = torch.argmax(output.start_logits)\n",
    "    end_idx = torch.argmax(output.end_logits)\n",
    "    predicted_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_idx:end_idx + 1]))\n",
    "\n",
    "    return predicted_answer.lower() == given_answer.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "q9rmuwDMD7Wi"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "VG56N52nDjJD"
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "total_count = 100\n",
    "\n",
    "for i in tqdm(range(total_count)):\n",
    "    correct_count += evaluate_instance(squad['train'][i], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1727708050401,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "uSGVjs8kDqL4"
   },
   "outputs": [],
   "source": [
    "# Calculate and output the accuracy\n",
    "accuracy = correct_count / total_count\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWQNU-P-G_Dt"
   },
   "source": [
    "# Track Metrics on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727708050402,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "mN9T67Wa27MT"
   },
   "outputs": [],
   "source": [
    "pip install torch_tb_profiler\n",
    "tensorboard --logdir=./log\n",
    "http://localhost:6006/#pytorch_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727708050402,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "B6GtTRqHyJ45"
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727708050403,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "nuZ3q6ihyUQM"
   },
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#model.freeze()\n",
    "#test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727708050403,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "0BYFzVzIyaXB"
   },
   "outputs": [],
   "source": [
    "# I try this when Colab runs out of Cuda memory\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727708050403,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "K2D5c1E3ydVb"
   },
   "outputs": [],
   "source": [
    "#!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1727708050404,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "TqVADbicyfIS"
   },
   "outputs": [],
   "source": [
    "#!ps -aux|grep python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1727708050404,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "j3lPgWk7yk9q"
   },
   "outputs": [],
   "source": [
    "# This is the best way to free up GPU memory - kill the ipykernel process\n",
    "#!kill -9 1129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727708050404,
     "user": {
      "displayName": "Nissi Kazembe",
      "userId": "03425949553883490603"
     },
     "user_tz": -120
    },
    "id": "ZLMwLtqaytfF"
   },
   "outputs": [],
   "source": [
    "## Trying out the LR Find method in Pytorch Lightning.  This won't work for multi gpu situations.  Wasn't happy with the initial results of the Learning rate finder.\n",
    "## This code won't work without defining bert_imdb variable\n",
    "## bert_ner = NERModel(transformer = transformer_model, n_tags = len(tag_complete))\n",
    "## trainer = pl.Trainer(gpus=1, max_epochs=1, auto_lr_find=True)\n",
    "\n",
    "# Run learning rate finder\n",
    "# lr_finder = trainer.fit(bert_ner)\n",
    "\n",
    "# Results can be found in\n",
    "# lr_finder.results\n",
    "\n",
    "# Plot with\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMSpidzfQb+gDee3GLDqdr2",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
